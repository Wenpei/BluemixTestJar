{
    "collab_server" : "",
    "contents" : "spssonspark.demo <- function(){\n  Sys.setenv(SPARK_HOME = \"C:\\\\aWorkFolder\\\\spark\\\\spark-1.6.0-bin-hadoop2.6\\\\spark-1.6.0-bin-hadoop2.6\")\n  sc <- sparkR.init(master = \"local[*]\", sparkEnvir = list(spark.driver.memory=\"2g\"))\n  data(iris)\n  sqlContext <- sparkRSQL.init(sc)\n  df <- createDataFrame(sqlContext, iris)\n  twostep <- SparkR:::callJStatic(\"com.ibm.spss.ml.clustering.TwoStep\",\"apply\")\n  SparkR:::callJMethod(twostep,\"setInputFieldList\",as.array(c(\"Sepal_Length\",\"Sepal_Width\")))\n  twostpmodel <- SparkR:::callJMethod(twostep,\"fit\",df@sdf)\n  SparkR:::callJMethod(twostpmodel,\"toPMML\")\n  #SparkR:::callJMethod(twostpmodel,\"statXML\")\n  SparkR:::callJMethod(twostpmodel,\"uid\")\n}\n\nspssonspark.demo2 <- function(){\n  Sys.setenv(SPARK_HOME = \"C:\\\\aWorkFolder\\\\spark\\\\spark-1.6.0-bin-hadoop2.6\\\\spark-1.6.0-bin-hadoop2.6\")\n  sc <- sparkR.init(master = \"local[*]\", sparkEnvir = list(spark.driver.memory=\"2g\"))\n  data(iris)\n  sqlContext <- sparkRSQL.init(sc)\n  df <- createDataFrame(sqlContext, iris)\n  twostepwrapper <- SparkR:::callJStatic(\"com.ibm.spss.ml.r.TwoStepWrapper\",\"fit\",\n                                         df@sdf,as.array(c(\"Sepal_Length\",\"Sepal_Width\")),as.array(c(\"\")),TRUE,TRUE,TRUE)\n  scoredf <- SparkR:::callJMethod(twostepwrapper,\"transform\",df@sdf)\n  scoredf <- SparkR:::dataFrame(scoredf)\n  head(scoredf)\n}\n\ntwostep <- function(\n  #  formula,\n  data,\n  inputFieldList = c(\"\"),\n  standardizeFieldList = c(\"\"),\n  autoClustering = TRUE,\n  featureSelection = TRUE,\n  outlierHandling = TRUE,\n  ...\n){\n  twostep <- SparkR:::callJStatic(\"com.ibm.spss.ml.clustering.TwoStep\",\"apply\")\n  SparkR:::callJMethod(twostep,\"setInputFieldList\",as.array(inputFieldList))\n  SparkR:::callJMethod(twostep,\"setStandardizeFieldList\",as.array(standardizeFieldList))\n  SparkR:::callJMethod(twostep,\"setAutoClustering\",autoClustering)\n  SparkR:::callJMethod(twostep,\"setFeatureSelection\",featureSelection)\n  SparkR:::callJMethod(twostep,\"setOutlierHandling\",outlierHandling)\n  advanceArgs = list(...)\n  print(advanceArgs)\n  lapply(seq_along(advanceArgs), function(i){\n    name <- names(advanceArgs[i])\n    #value <- advanceArgs[[i]]\n    head <- toupper(substr(name,0,1))\n    tril <- substring(name,2)\n    name <- paste(\"set\",head,tril,sep=\"\")\n    print(name)\n    print(advanceArgs[[i]])\n    SparkR:::callJMethod(twostep,name,advanceArgs[[i]])\n  })\n\n  twostepmodel <- SparkR:::callJMethod(twostep,\"fit\",df@sdf)\n\n  return(new(\"PipelineModel\", model = twostepmodel))\n}\n\ntwostep <- function(){\n  library(SparkR)\n  Sys.setenv(SPARK_HOME = \"C:\\\\aWorkFolder\\\\spark\\\\spark-1.6.0-bin-hadoop2.6\\\\spark-1.6.0-bin-hadoop2.6\")\n  sc <- sparkR.init(master = \"local[*]\", sparkEnvir = list(spark.driver.memory=\"2g\"))\n  data(iris)\n  sqlContext <- sparkRSQL.init(sc)\n  df <- createDataFrame(sqlContext, iris)\n  twostepmodel <- clustering.twostep(df,Species~.)\n  scoredata <- spss.predict(twostepmodel,df)\n  head(scoredata)\n}\n\nlinear <- function(){\n  library(SparkR)\n  Sys.setenv(SPARK_HOME = \"C:\\\\aWorkFolder\\\\spark\\\\spark-1.6.0-bin-hadoop2.6\\\\spark-1.6.0-bin-hadoop2.6\")\n  sc <- sparkR.init(master = \"local[*]\", sparkEnvir = list(spark.driver.memory=\"2g\"))\n  data(iris)\n  sqlContext <- sparkRSQL.init(sc)\n  df <- createDataFrame(sqlContext, iris)\n  linearmodel <- classificationandregression.linearregression(df,Species~.)\n  scoredata <- spss.predict(linearmodel,df)\n  head(scoredata)\n}\n",
    "created" : 1480492548403.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2228413019",
    "id" : "95FE5F65",
    "lastKnownWriteTime" : 1480660642,
    "last_content_update" : 1480660642842,
    "path" : "C:/aWorkFolder/gitibm/project/spark-spss-r-pkg/SPSSonSparkR/R/demo.R",
    "project_path" : "R/demo.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}