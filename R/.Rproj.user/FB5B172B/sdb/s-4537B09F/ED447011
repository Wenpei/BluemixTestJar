{
    "collab_server" : "",
    "contents" : "setOldClass(\"jobj\")\n\n#' S4 class that represents an TwoStep Model\n#'\n#' @param jobj a Java object reference to the Wrapper\n#' @export\n#' @note TwoStep for SPSS on SPARK\nTwoStepModel <-\n  setClass(\"TwoStepModel\", slots = c(name = \"character\"), contains = \"SPSSModel\")\n#setClass(\"TwoStepModel\", representation(jobj = \"jobj\"))\n\n#' Two-Step Cluster\n#'\n#'\n#' Scalable Two-Step is based on the familiar two-step clustering algorithm but extends both\n#' its functionality and performance in several directions.\n#' First, it can effectively work with large and distributed data supported by Spark that\n#' provides the Map-Reduce computing paradigm.\n#' Second, the algorithm provides mechanisms for selecting the most relevant features for\n#' clustering the given data, as well as detecting rare outlier points. Moreover, it provides\n#' an enhanced set of evaluation and diagnostic features for enabling insight.\n#' The algorithm of two-step clustering first performs a pre-clustering step by scanning the\n#' entire dataset and storing the dense regions of data cases in terms of summary statistics\n#' called cluster features. The cluster features are stored in memory in a data structure\n#' called the CF-tree. Finally, an agglomerative hierarchical clustering algorithm is applied\n#' to cluster the set of cluster features.\n\n#' @param inputFieldList Param for a list of input fields.\n#' @param categoryMajorityThreshold Categorical fields with a percentage of cases in a single category\n#'                        greater than the specified value are excluded from the analysis. The value\n#'                        must be greater than 0 and less than 1. Default: 0.95.\n#' @param outlierHandling Param for outlier handling option. Default: true.\n#' @param maxClusterNum Param for the upper range of cluster number if it's RANGE. Must be >\n#'                        0. Default: 15.\n#' @param autoClusteringMethod If you set autoClustering = True, choose from the following\n#'                        clustering methods used to automatically determine the number of clusters: -\n#'                        \"CRITERION\": Information criteria convergence is the ratio of information\n#'                        criteria corresponding to two current cluster solutions and the first cluster\n#'                        solution. The criterion used is the one selected in the Clustering Criterion\n#'                        group. - \"DISTANCEJUMP\": Distance jump is the ratio of distances corresponding\n#'                        to two consecutive cluster solutions. - \"MAXIMUM\": Combine results from the\n#'                        information criteria convergence method and the distance jump method to\n#'                        produce the number of clusters corresponding to the second jump. - \"MINIMUM\":\n#'                        Combine results from the information criteria convergence method and the\n#'                        distance jump method to produce the number of clusters corresponding to the\n#'                        first jump Default: MINIMUM\n#' @param standardizeFieldList Parameter for specifying one set of input continuous fields that\n#'                        needs to be standardized. Every field in this set must have two statistics\n#'                        \"mean\" and \"variance\" in the input data model, otherwise this field will be\n#'                        not standardized. For example about data model: <Field measure=\"continuous\"\n#'                        name=\"Cost\" role=\"input\" storage=\"real\"> <ContinuousStatistics mean=\"54.909\"\n#'                        variance=\"806.252\" sumCompWts=\"200\" sumFreqWts=\"200\"/> </Field>\n#' @param featureImportanceMethod Feature Importance Method determines how important the features\n#'                        (fields) are in the cluster solution. The output includes information about\n#'                        overall feature importance and the importance of each feature field in each\n#'                        cluster. Features that do not meet a minimum threshold are excluded: -\n#'                        \"CRITERION\": Based on the criterion that is selected in the Clustering\n#'                        Criterion group. - \"EFFECTSIZE\": Feature importance is based on effect size\n#'                        instead of significance values. Default: CRITERION\n#' @param featureSelection Param for doing adaptive feature selection or not. Default: true. The\n#'                        adaptive feature selection is a heavyweight operation,so it's time-consuming;\n#'                        the required time is proportional to the number of fields.\n#' @param maxEntNonLeaf Param for the max number of entries that a non leaf node can hold.\n#'                        Must be > 0. Default: 8.\n#' @param missingValueThreshold Param for the portion of missing value in any feature. Must be >= 0\n#'                        and <= 1. Default: 0.7. If the missing value portion larger than this value,\n#'                        exclude the feature.\n#' @param outlierClusterNum Parameter for specifying the number of the most extreme outlier\n#'                        clusters. Must be > 0. Default: 20. Use to specify the number outliers to\n#'                        export, used only on outlierHandling=true.\n#' @param outlierThreshold Param for leaf entry which contains less than this value will\n#'                        consider as outlier. Must be >= 2. Default: 10.\n#' @param maxEntLeaf Param for the max number of entries that a leaf node can hold. Must\n#'                        be > 1. Default: 8.\n#' @param minFrequency Param for the minimum portion of feature frequency in Feature\n#'                        Selection. Must be > 0 and < 1. Default: 0.5. This parameter is used for\n#'                        adaptive feature selection.\n#' @param autoClustering If set to True, the algorithm will automatically determine the best\n#'                        number of clusters, within the specified range. Default: true.\n#' @param sigLevel Param for significance level for computing feature importance. Must\n#'                        be > 0 and < 1. Default: 0.05. This is used only when\n#'                        featureImpoMethod=EFFECTSIZE.\n#' @param featureFiltering Param for doing feature filtering or not. Default: true.\n#' @param coefficientThreshold Param for the limit of coefficient of variation of a continuous\n#'                        feature. Must be >= 0 and <= 1. Default: 0.05. If the coefficient of variation\n#'                        of a continuous feature is smaller than this value, exclude the feature.\n#' @param categoryCountThreshold Categorical fields with more than the specified number of categories\n#'                        are excluded from the analysis. The value must be a positive integer greater\n#'                        than 0. Default: 24.\n#' @param distMeasure This selection determines how the similarity between two clusters is\n#'                        computed: - \"LOGLIKELIHOOD\": The likelihood measure places a probability\n#'                        distribution on the fields. Continuous fields are assumed to be normally\n#'                        distributed, while categorical fields are assumed to be multinomial. All\n#'                        fields are assumed to be independent. - \"EUCLIDEAN\": The Euclidean measure is\n#'                        the \"straight line\" distance between two clusters. Squared Euclidean measure\n#'                        and the Ward method are used to compute similarity between clusters. It can be\n#'                        used only when all of the fields are continuous. Default: LOGLIKELIHOOD\n#' @param maxTreeHeight Param for maximum height of the Tree. Must be > 0. Default: 3.\n#' @param minClusterNum Param for the lower range of cluster number if it's RANGE. Must be >\n#'                        1. Default: 2. This value should smaller or equal with maxClusterNum.\n#' @param fixedClusterNum Param for the number of cluster if it's FIXED. Must be > 1. Default:\n#'                        5.\n#' @param informationCriterion This selection controls how the automatic clustering algorithm\n#'                        determines the number of clusters: - \"BIC\": A measure for selecting and\n#'                        comparing models based on the -2 log likelihood. Smaller values indicate\n#'                        better models. The BIC also \"penalizes\" overparameterized models (complex\n#'                        models with a large number of inputs, for example), but more strictly than the\n#'                        AIC. - \"AIC\": A measure for selecting and comparing models based on the -2 log\n#'                        likelihood. Smaller values indicate better models. The AIC \"penalizes\"\n#'                        overparameterized models (complex models with a large number of inputs, for\n#'                        example). Default: BIC\n#' @name clustering.twostep\n#' @export\n#' @examples\n#' \\dontrun{\n#' sc <- sparkR.init()\n#' data(iris)\n#' sqlContext <- sparkRSQL.init(sc)\n#' df <- createDataFrame(sqlContext, iris)\n#' twostepmodel <- clustering.twostep(df,~Sepal_Length+Sepal_Width)\n#'\n#' scoredata <- spss.predict(twostepmodel,df)\n#' head(scoredata)\n#' }\nsetMethod(\"clustering.twostep\", signature(data = \"DataFrame\"),\n          function(\n            data,\n            formula = NULL,\n            inputFieldList = c(),\n            standardizeFieldList = c(),\n            autoClustering = TRUE,\n            featureSelection = TRUE,\n            outlierHandling = TRUE,\n            ...){\n            TwoStepModel(\n                SPSSModel(jobj = spss.TwoStep.fit(data, formula, inputFieldList, standardizeFieldList,\n                                                  autoClustering = autoClustering,\n                                                  featureSelection = featureSelection,\n                                                  outlierHandling = outlierHandling,\n                                                  ...)),\n                name = \"TwoStepModel\")\n          })\n\n# Major function call for twostep\nspss.TwoStep.fit <- function(\n  data,\n  formula,\n  inputFieldList,\n  standardizeFieldList,\n  ...\n){\n  twostep <- SparkR:::callJStatic(\"com.ibm.spss.ml.clustering.TwoStep\",\"apply\")\n  advanceArgs = list(...)\n  lapply(seq_along(advanceArgs), function(i){\n    parameterName <- names(advanceArgs[i])\n    head <- toupper(substr(parameterName,0,1))\n    tril <- substring(parameterName,2)\n    functionName <- paste(\"set\",head,tril,sep=\"\")\n    #print(functionName)\n    value <- spss.util.parameterSwitch(spss.TwoStep.parameterType, parameterName, advanceArgs[[i]])\n    print(paste(functionName, \"(\", value, \")\"))\n    SparkR:::callJMethod(twostep,functionName,value)\n  })\n  print(\"Done Parameter set\")\n  if(!is.null(formula)){\n    formula <- paste(deparse(formula), collapse = \"\")\n    rmodel <- SparkR:::callJStatic(\"com.ibm.spss.ml.r.RWrapper\",\"fitWithRFormula\", twostep, formula, df@sdf)\n  }else{\n    SparkR:::callJMethod(twostep,\"setInputFieldList\",as.array(inputFieldList))\n    if(!is.null(standardizeFieldList))\n      SparkR:::callJMethod(twostep,\"setStandardizeFieldList\",as.array(standardizeFieldList))\n    rmodel <- SparkR:::callJStatic(\"com.ibm.spss.ml.r.RWrapper\",\"fit\", twostep, df@sdf)\n  }\n  rmodel\n}\n\nsetMethod(\"spss.summary\", signature(object = \"TwoStepModel\"),\n          function(object){\n            summary = SparkR:::callJMethod(object@jobj,\"summary\")\n            list(\n              modelgoodness = SparkR:::callJMethod(summary,\"get\",\"modelgoodness\"),\n              modelcriterion = SparkR:::callJMethod(summary,\"get\",\"modelcriterion\"))\n          })\n\nspss.TwoStep.parameterType <- list(\n  categoryMajorityThreshold = \"DoubleParam\",\n  outlierHandling = \"BooleanParam\",\n  maxClusterNum = \"IntParam\",\n  autoClusteringMethod = \"Param[String]\",\n  standardizeFieldList = \"StringArrayParam\",\n  featureImportanceMethod = \"Param[String]\",\n  featureSelection = \"BooleanParam\",\n  maxEntNonLeaf = \"IntParam\",\n  missingValueThreshold = \"DoubleParam\",\n  outlierClusterNum = \"IntParam\",\n  outlierThreshold = \"IntParam\",\n  maxEntLeaf = \"IntParam\",\n  minFrequency = \"DoubleParam\",\n  autoClustering = \"BooleanParam\",\n  sigLevel = \"DoubleParam\",\n  featureFiltering = \"BooleanParam\",\n  coefficientThreshold = \"DoubleParam\",\n  categoryCountThreshold = \"IntParam\",\n  distMeasure = \"Param[String]\",\n  maxTreeHeight = \"IntParam\",\n  minClusterNum = \"IntParam\",\n  fixedClusterNum = \"IntParam\",\n  informationCriterion = \"Param[String]\"\n)\n",
    "created" : 1480492538575.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4028162421",
    "id" : "ED447011",
    "lastKnownWriteTime" : 1480662232,
    "last_content_update" : 1480662232326,
    "path" : "C:/aWorkFolder/gitibm/project/spark-spss-r-pkg/SPSSonSparkR/R/twostep.R",
    "project_path" : "R/twostep.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}